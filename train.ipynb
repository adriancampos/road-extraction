{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "!jupyter notebook list\n",
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import tiramisu\n",
    "from models import unet\n",
    "from datasets import deepglobe\n",
    "from datasets import maroads\n",
    "from datasets import joint_transforms\n",
    "import utils.imgs\n",
    "import utils.training as train_utils\n",
    "\n",
    "# tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Download the DeepGlobe dataset from https://competitions.codalab.org/competitions/18467. Place it in datasets/deepglobe/dataset/train,test,valid\n",
    "Download the Massachusetts Road Dataset from https://www.cs.toronto.edu/~vmnih/data/. Combine the training, validation, and test sets, process with `crop_dataset.ipynb` and place the output in datasets/maroads/dataset/map,sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = \"exp0.1_small\"\n",
    "DEEPGLOBE_PATH = Path('datasets/', 'deepglobe/dataset')\n",
    "MAROADS_PATH = Path('datasets/', 'maroads/dataset')\n",
    "RESULTS_PATH = Path('.results/')\n",
    "WEIGHTS_PATH = Path('.weights/')\n",
    "RUNS_PATH    = Path('.runs/')\n",
    "RESULTS_PATH.mkdir(exist_ok=True)\n",
    "WEIGHTS_PATH.mkdir(exist_ok=True)\n",
    "RUNS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "batch_size = 1 # TODO: Should be `MAX_BATCH_PER_CARD * torch.cuda.device_count()` (which in this case is 1 assuming max of 1 batch per card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# resize = joint_transforms.JointRandomCrop((300, 300))\n",
    "\n",
    "normalize = transforms.Normalize(mean=deepglobe.mean, std=deepglobe.std)\n",
    "train_joint_transformer = transforms.Compose([\n",
    "#     resize,\n",
    "    joint_transforms.JointRandomHorizontalFlip(),\n",
    "    joint_transforms.JointRandomVerticalFlip(),\n",
    "    joint_transforms.JointRandomRotate()\n",
    "    ])\n",
    "\n",
    "train_slice = slice(None,4000)\n",
    "test_slice = slice(4000,None)\n",
    "\n",
    "train_dset = deepglobe.DeepGlobe(DEEPGLOBE_PATH, 'train', slc = train_slice,\n",
    "    joint_transform=train_joint_transformer,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ColorJitter(brightness=.4,contrast=.4,saturation=.4),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "train_dset_ma = maroads.MARoads(MAROADS_PATH, \n",
    "    joint_transform=train_joint_transformer,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ColorJitter(brightness=.4,contrast=.4,saturation=.4),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "# print(len(train_dset_ma.imgs))\n",
    "# print(len(train_dset_ma.msks))\n",
    "train_dset_combine = torch.utils.data.ConcatDataset((train_dset, train_dset_ma))\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "# train_loader = torch.utils.data.DataLoader(train_dset_ma, batch_size=batch_size, shuffle=True)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dset_combine, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# resize_joint_transformer = transforms.Compose([\n",
    "#     resize\n",
    "#     ])\n",
    "resize_joint_transformer = None\n",
    "val_dset = deepglobe.DeepGlobe(\n",
    "    DEEPGLOBE_PATH, 'valid', joint_transform=resize_joint_transformer,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]))\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_dset = deepglobe.DeepGlobe(\n",
    "    DEEPGLOBE_PATH, 'train', joint_transform=resize_joint_transformer, slc = test_slice,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]))\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train: %d\" %len(train_loader.dataset))\n",
    "print(\"Val: %d\" %len(val_loader.dataset.imgs))\n",
    "print(\"Test: %d\" %len(test_loader.dataset.imgs))\n",
    "# print(\"Classes: %d\" % len(train_loader.dataset.classes))\n",
    "\n",
    "print((iter(train_loader)))\n",
    "\n",
    "inputs, targets = next(iter(train_loader))\n",
    "print(\"Inputs: \", inputs.size())\n",
    "print(\"Targets: \", targets.size())\n",
    "\n",
    "utils.imgs.view_image(inputs[0])\n",
    "# utils.imgs.view_image(targets[0])\n",
    "utils.imgs.view_annotated(targets[0])\n",
    "\n",
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-4\n",
    "LR_DECAY = 0.995\n",
    "DECAY_EVERY_N_EPOCHS = 1\n",
    "N_EPOCHS = 1000\n",
    "torch.cuda.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.bceloss import dice_bce_loss\n",
    "from loss.BCESSIM import BCESSIM\n",
    "\n",
    "# model = tiramisu.FCDenseNet67(n_classes=2).cuda()\n",
    "# model = tiramisu.FCDenseNetSmall(n_classes=1).cuda()\n",
    "model = unet.UNet(n_classes=1).cuda()\n",
    "# model.apply(train_utils.weights_init)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "# criterion = nn.NLLLoss2d(weight=deepglobe.class_weight.cuda()).cuda()\n",
    "# criterion = nn.NLLLoss().cuda() ##\n",
    "\n",
    "\n",
    "# criterion = dice_bce_loss()\n",
    "criterion = BCESSIM()\n",
    "\n",
    "# criterion = nn.NLLLoss2d(reduce=False).cuda()\n",
    "# criterion = nn.CrossEntropyLoss().cuda()\n",
    "# criterion = nn.NLLLoss2d().cuda()\n",
    "# criterion = dice_bce_loss()\n",
    "# criterion = nn.BCELoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "# start_epoch = train_utils.load_weights(model, (train_utils.WEIGHTS_PATH+'latest.th'))\n",
    "print(\"Starting from epoch\", start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writer will output to ./runs/ directory by default\n",
    "writer = SummaryWriter(log_dir=(RUN_PATH.as_posix() + \"/\" + \"run\" + str(run) + \"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_loader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "# break # errors. Used to stop \"run all\"\n",
    "for epoch in range(start_epoch, N_EPOCHS+1):\n",
    "    since = time.time()\n",
    "\n",
    "    ### Train ###\n",
    "    trn_loss, trn_err = train_utils.train(\n",
    "        model, train_loader, optimizer, criterion, epoch)\n",
    "    print('Epoch {:d}\\nTrain - Loss: {:.4f}, Acc: {:.4f}'.format(\n",
    "        epoch, trn_loss, 1-trn_err))    \n",
    "    time_elapsed = time.time() - since  \n",
    "    print('Train Time {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "#     ### Test ###\n",
    "#     val_loss, val_err = train_utils.test(model, val_loader, criterion, epoch)    \n",
    "#     print('Val - Loss: {:.4f} | Acc: {:.4f}'.format(val_loss, 1-val_err))\n",
    "#     time_elapsed = time.time() - since  \n",
    "#     print('Total Time {:.0f}m {:.0f}s\\n'.format(\n",
    "#         time_elapsed // 60, time_elapsed % 60))\n",
    "#     val_loss = trn_loss\n",
    "#     val_err = trn_err\n",
    "    ### Test ###\n",
    "    tes_loss, tes_err, tes_iou = train_utils.test(model, test_loader, criterion, epoch)    \n",
    "    print('Tes - Loss: {:.4f} | Acc: {:.4f}'.format(tes_loss, 1-tes_err))\n",
    "    time_elapsed = time.time() - since  \n",
    "    print('Total Time {:.0f}m {:.0f}s\\n'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    val_loss = trn_loss\n",
    "    val_err = trn_err\n",
    "    \n",
    "    ### Checkpoint ###    \n",
    "    train_utils.save_weights(model, epoch, tes_loss, tes_err)\n",
    "\n",
    "    ### Adjust Lr ###\n",
    "#     train_utils.adjust_learning_rate(LR, LR_DECAY, optimizer, \n",
    "#                                      epoch, DECAY_EVERY_N_EPOCHS)\n",
    "    \n",
    "    # Log on tensorboard\n",
    "    writer.add_scalar('Loss/train', trn_loss, epoch)\n",
    "    writer.add_scalar('Loss/test', tes_loss, epoch)\n",
    "    \n",
    "    writer.add_scalar('Error/train', trn_err, epoch)\n",
    "    writer.add_scalar('Error/test', tes_err, epoch)\n",
    "    \n",
    "#     writer.add_scalar('Accuracy/train', trn_iou, epoch)\n",
    "    writer.add_scalar('Accuracy/test', tes_iou, epoch)\n",
    "    \n",
    "#     writer.add_scalar('Accuracy/train', epoch_acc, epoch)\n",
    "#     writer.add_scalar('Accuracy/test/noaug', do_valid(False), epoch)\n",
    "#     writer.add_scalar('Accuracy/test/tta', do_valid(True), epoch)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        writer.add_scalar('Params/learning_rage', param_group['lr'], epoch)\n",
    "#     writer.add_scalar('params/learning_rate', optimizer.lr, epoch)\n",
    "#     writer.add_scalar('Params/no_optim', no_optim, epoch)\n",
    "\n",
    "    # show a sample image\n",
    "    for i in range(3):\n",
    "        inputs, targets, pred, loss, err, iou = train_utils.get_sample_predictions(model, test_loader, n=1, criterion=criterion)\n",
    "#         print(inputs.shape)\n",
    "        raw = model(inputs.cuda()).cpu()\n",
    "#         print(raw.shape)\n",
    "#         print(pred.shape)\n",
    "\n",
    "# #         img = pred\n",
    "        \n",
    "# #         img = torchvision.utils.make_grid([inputs, targets, pred], nrow=8, padding=2, normalize=False, range=None, scale_each=False, pad_value=0)\n",
    "        \n",
    "# #         img = torchvision.utils.make_grid(torch.stack([inputs[0], targets[0], pred[0].float().float()]))\n",
    "# #         print(inputs.shape)\n",
    "# #         print(targets.shape)\n",
    "# #         print(pred.shape)\n",
    "        \n",
    "#         # print stats on raw\n",
    "#         print(\"max\", raw.max())\n",
    "#         print(\"min\", raw.min())\n",
    "        \n",
    "        \n",
    "        img = torchvision.utils.make_grid(torch.stack([\n",
    "            inputs[0],\n",
    "            targets[0].unsqueeze(0).expand(3,-1,-1).float(), \n",
    "            pred[0].unsqueeze(0).expand(3,-1,-1).float(),\n",
    "            raw[0].expand(3,-1,-1).float()\n",
    "        ]), normalize=True)\n",
    "        \n",
    "\n",
    "        writer.add_image('test/sample_pred', img, epoch)\n",
    "        break\n",
    "    \n",
    "    start_epoch = epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns test_loss, test_error, jaccard\n",
    "train_utils.test(model, test_loader, criterion, epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = train_utils.view_sample_predictions(model, test_loader, n=1, criterion=criterion)\n",
    "print(\"loss\", \"error\", \"jaccard\")\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
